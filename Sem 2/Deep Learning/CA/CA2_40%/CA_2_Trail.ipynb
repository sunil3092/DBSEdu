{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.caltech.edu/records/20098"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "ROOT = '../../../../../DataSets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_RATIO = 0.8\n",
    "\n",
    "data_dir = os.path.join(ROOT, 'CUB_200_2011')\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(test_dir)\n",
    "\n",
    "classes = os.listdir(images_dir)\n",
    "\n",
    "for c in classes:\n",
    "\n",
    "    class_dir = os.path.join(images_dir, c)\n",
    "\n",
    "    images = os.listdir(class_dir)\n",
    "\n",
    "    n_train = int(len(images) * TRAIN_RATIO)\n",
    "\n",
    "    train_images = images[:n_train]\n",
    "    test_images = images[n_train:]\n",
    "\n",
    "    os.makedirs(os.path.join(train_dir, c), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_dir, c), exist_ok=True)\n",
    "\n",
    "    for image in train_images:\n",
    "        image_src = os.path.join(class_dir, image)\n",
    "        image_dst = os.path.join(train_dir, c, image)\n",
    "        shutil.copyfile(image_src, image_dst)\n",
    "\n",
    "    for image in test_images:\n",
    "        image_src = os.path.join(class_dir, image)\n",
    "        image_dst = os.path.join(test_dir, c, image)\n",
    "        shutil.copyfile(image_src, image_dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated means: tensor([0.4862, 0.4999, 0.4315])\n",
      "Calculated stds: tensor([0.1821, 0.1811, 0.1931])\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.ImageFolder(root=train_dir,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim=(1, 2))\n",
    "    stds += torch.std(img, dim=(1, 2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "\n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_size = 224\n",
    "pretrained_means = [0.485, 0.456, 0.406]\n",
    "pretrained_stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(pretrained_size),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomCrop(pretrained_size, padding=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=pretrained_means,\n",
    "                         std=pretrained_stds)\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize(pretrained_size),\n",
    "    transforms.CenterCrop(pretrained_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=pretrained_means,\n",
    "                         std=pretrained_stds)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root=train_dir,\n",
    "                                  transform=train_transforms)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir,\n",
    "                                 transform=test_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_RATIO = 0.9\n",
    "\n",
    "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
    "n_valid_examples = len(train_data) - n_train_examples\n",
    "\n",
    "train_data, valid_data = data.random_split(train_data,\n",
    "                                           [n_train_examples, n_valid_examples])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = copy.deepcopy(valid_data)\n",
    "valid_data.dataset.transform = test_transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('dbsenvalt')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b69cd713fd987fe7d1cd2532bcfe146cd06eada8a7acd24118ab58f0a54103e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
